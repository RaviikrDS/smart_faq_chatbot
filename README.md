
# ğŸ§  Smart FAQ Chatbot

A lightweight, free, and fully local chatbot for answering common questions using document embeddings â€” powered by FAISS, HuggingFaceEmbeddings, and a FastAPI + Streamlit stack.

---

## ğŸ“Œ Use Case

This chatbot is ideal for:
- ğŸ“‹ Customer support portals (answering FAQs)
- ğŸ¢ Internal HR or IT helpdesks
- ğŸ« College or course FAQs
- ğŸ§¾ Policy bots (company rules, return/shipping policy, etc.)

Unlike generative AI models (which can hallucinate), this system retrieves only verified answers from your uploaded content â€” making it accurate, safe, and free.

---

## ğŸ”­ Future Scope

- âœ… Add an LLM (like GPT4All or LLaMA) for answer generation
- ğŸŒ Host frontend with Streamlit Cloud, backend with Render
- ğŸ§¾ Upload PDFs, TXT, DOCX files (not just CSV)
- ğŸ” Add authentication
- ğŸ§  Summarize long documents using chunking + LLM
- ğŸŒ Multilingual Q&A via translation pipelines

---

## ğŸ§± Folder Structure

```
smart_faq_chatbot/
â”œâ”€â”€ backend/                    # FastAPI backend with FAISS and LangChain
â”‚   â”œâ”€â”€ main.py                # API routes and retrieval logic
â”‚   â”œâ”€â”€ faq.csv                # Your FAQ data (Question, Answer)
â”‚   â”œâ”€â”€ requirements.txt       # Backend dependencies
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ create_index.py    # Script to build FAISS vector index
â”‚   â””â”€â”€ vector_store/          # Auto-created FAISS index store
â”‚
â”œâ”€â”€ frontend/                   # Streamlit frontend
â”‚   â”œâ”€â”€ app.py                 # Streamlit UI
â”‚   â”œâ”€â”€ requirements.txt       # Frontend dependencies
â”‚   â””â”€â”€ .streamlit/config.toml # (Optional) Port/CORS settings
```

---

## âš™ï¸ Architecture

```
User â†’ Streamlit UI â†’ FastAPI â†’ FAISS (via LangChain) â†’ Answer
                          â†“
                  HuggingFace Embeddings
```

### ğŸ“š Data Flow:

1. User asks a question in UI
2. Frontend sends it to FastAPI via `/query`
3. FastAPI uses FAISS + Embeddings to find the most similar FAQ answer
4. The matched answer is returned

---

## ğŸ§ª Components Explained

| Component | Technology | Purpose |
|----------|------------|---------|
| `faq.csv` | CSV | Source of truth for Q&A pairs |
| `HuggingFaceEmbeddings` | sentence-transformers | Convert answers to dense vectors |
| `FAISS` | Facebook AI Similarity Search | Store and retrieve embeddings efficiently |
| `FastAPI` | Backend API | Receives question, returns answer |
| `Streamlit` | UI | Simple web interface for interaction |

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Backend Setup

```bash
cd backend
python -m venv venv
venv\Scripts\activate          # or source venv/bin/activate (Linux/Mac)
pip install -r requirements.txt
python utils/create_index.py    # builds FAISS index
uvicorn main:app --port 10000
```

---

### 2ï¸âƒ£ Frontend Setup

```bash
cd frontend
pip install -r requirements.txt
streamlit run app.py
```

Access frontend at:
```
http://localhost:8501
```

---

## ğŸ§  Example Questions

| Question | Answer |
|---------|--------|
| What is your return policy? | You can return items within 30 days. |
| How can I track my order? | Log in and check the 'My Orders' section. |

---

## ğŸ› ï¸ Requirements

| Dependency | Version |
|------------|---------|
| Python | 3.9+ |
| FAISS | faiss-cpu |
| LangChain | langchain, langchain-community |
| Hugging Face | sentence-transformers |
| Streamlit | 1.20+ |
| FastAPI & Uvicorn | Latest |

---

## ğŸŒ Deployment

- ğŸ“¦ Backend: Deploy on [Render](https://render.com)
- ğŸ¯ Frontend: Deploy on [Streamlit Cloud](https://streamlit.io/cloud)
- ğŸ” Add secrets for keys or future LLMs via `.env` or cloud env settings

---

## ğŸ Credits

- Built using [LangChain](https://github.com/langchain-ai/langchain)
- Embeddings: `all-MiniLM-L6-v2` from `sentence-transformers`
- Inspired by RAG (Retrieval-Augmented Generation) pipelines
